[
  {
    "objectID": "RahulThakar.github.io.html",
    "href": "RahulThakar.github.io.html",
    "title": "RahulThakar.github.io",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "RahulThakar.github.io.html#quarto",
    "href": "RahulThakar.github.io.html#quarto",
    "title": "RahulThakar.github.io",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "DVAssignments.html",
    "href": "DVAssignments.html",
    "title": "Data Visualization Assignments",
    "section": "",
    "text": "Assignment 1"
  },
  {
    "objectID": "DVAssignment1.html",
    "href": "DVAssignment1.html",
    "title": "Data Visualization Assignment 1",
    "section": "",
    "text": "Assignment 1\nFall (Red Color)\n\n\n\nFall (Red Color)\n\n\n\n## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\n\n\n## Simple version\n\nplot(anscombe$x1,anscombe$y1)\n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n\n\n\n\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n\n\n\n\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n\n\n\n\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\n\n\n\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)\n\nCritique of the Graph\n\nThis graph shows us the returns to education versus cost of education over time. As per the graph, we see that the returns to education have remained constant over time while the costs have increased. Thus, the graphs suggests that there is not much to gain in terms of money when it comes to education.\nThe graph has several inconsistencies, the graph shows income of only the first year after a student graduates, however the income of the student may increase after the first year depending on the individual performance where his/her education may come handy.\nMoreover, this is highly aggregated data where the student income of different majors is being averaged. For example, some majors may be paid more while other majors may be paid less depending on market demand. Furthermore, this graph does not take into account different business cycles/economic cycles.\nThe graph also does not specify the demographics for example, is the graph talking about students who are citizens or students who are international. Furthermore, the students are also not categorized based on the racial and ethnic grounds to get a better understanding of what is happening with earnings as the students graduate. Moreover, many students may also choose to take a break after they graduate, to get a better job which might again skew averages.\nThus, we can get a better picture only after answering these questions satisfactorily.\nGenerative Art Examples"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "assignments",
    "section": "",
    "text": "Data Visualization Assignments\nMethods of Data Collection Assignments"
  },
  {
    "objectID": "assignments.html#assignment-section",
    "href": "assignments.html#assignment-section",
    "title": "assignments",
    "section": "",
    "text": "Data Visualization Assignments\nMethods of Data Collection Assignments"
  },
  {
    "objectID": "Tufte.html",
    "href": "Tufte.html",
    "title": "Tufte BlogPost",
    "section": "",
    "text": "In this engaging and exciting video by Dr. Tufte, he explains how data can be used to convey a story, which can be engaging and misleading at the same time. Dr. Tufte clears the misconception about the term “data,” where most people assume that data is something concrete, however, myriad, stories can be told using data.\nDr. Tufte’s discussion on the significance of data visualization is brought to life through compelling examples. From Galileo’s map to a music graph that dynamically captures every note and rhythm, these instances underscore the potent role of data visualization in data mapping.\nHe then transitions by stating that “brilliance is rare” and discussing why most research findings are false. These findings involve data that can be manipulated in any way the authors want the results to be. He then discusses the Phillip curve and functional MRI examples, where false positives are generated using a salmon. Furthermore, he also discusses the “Google flu of overfitting.” where you “torture the data long enough, it will tell you anything.”\nUsing these examples, the author then moves on to a more philosophical question of whether data is being used to reach the truth. He emphasizes the need for more exploratory studies rather than confirmatory studies, and the importance of data forensics. This attitude of ‘sampling to please’ needs to stop, and we cannot expect people to keep their own scores. He finally urges people to look at the real world and not representations. Finally, he then discusses the survival bias using the example of castles.\nThis was an eye-opening presentation by Dr. Tufte on how data can be weaponized for the purpose you want to achieve. Thus, it is important to use data to find the truth and for a noble cause. After this presentation, I will make sure that I will use data to get closer to reality. This presentation has also made me realize to view data critically and not believe the results of any paper blindly, so I will now question the results of papers and the graphs used in these papers.\nFurthermore, I will also question researchers on their findings and only accept results after thoroughly investigating the data sources and the methods used for data representation. This video has made me more aware of how I should read data and write and interpret my own reports generated from the data that I have used.\nFrom a practical standpoint, I will use data from suitable sources and not make any unnecessary assumptions about data. I will also be cautious about my surveys, making sure they are not biased in any way. I will use random sampling, which was discussed in class before, and will ask questions that the respondents are comfortable replying to. Therefore, this video has been an eyeopener for me and I will practically try to implement all that Dr. Tufte has highlighted in his video."
  }
]